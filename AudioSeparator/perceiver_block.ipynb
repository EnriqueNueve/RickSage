{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4c76b45",
   "metadata": {},
   "source": [
    "# Perceiver Block "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5ecb3c",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/4188/1*41GYOpmCItZMxO4V7U4FGw.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bd8de0",
   "metadata": {},
   "source": [
    "## Import modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f540a4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46155c4",
   "metadata": {},
   "source": [
    "## Perceiver 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d19fa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceiver2D(keras.Model):\n",
    "    \"\"\" \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dim: int \n",
    "        text text text \n",
    "    latent_dim: int \n",
    "        text text text \n",
    "    projection_dim: int \n",
    "        text text text \n",
    "    num_heads: int \n",
    "        Number of multihead attention units for transformer\n",
    "    num_transformer_blocks: int \n",
    "        Number of transformer blocks\n",
    "    ffn_units: list(int)\n",
    "        text text text \n",
    "    dropout_rate: float\n",
    "        Rate for dropout  \n",
    "    num_iterations: int\n",
    "        Number of times to pass input through perciever\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tf.constant \n",
    "        3D (feature,short_time,long_time) tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dim,\n",
    "        latent_dim,\n",
    "        projection_dim,\n",
    "        num_heads,\n",
    "        num_transformer_blocks,\n",
    "        ffn_units,\n",
    "        dropout_rate,\n",
    "        num_iterations,\n",
    "    ):\n",
    "        super(Perceiver2D, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.data_dim = data_dim\n",
    "        self.projection_dim = projection_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.num_transformer_blocks = num_transformer_blocks\n",
    "        self.ffn_units = ffn_units\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        \n",
    "    def create_ffn(self,hidden_units, dropout_rate):\n",
    "        ffn_layers = []\n",
    "        for units in hidden_units[:-1]:\n",
    "            ffn_layers.append(layers.Dense(units, activation=tf.nn.gelu))\n",
    "\n",
    "        ffn_layers.append(layers.Dense(units=hidden_units[-1]))\n",
    "        ffn_layers.append(layers.Dropout(dropout_rate))\n",
    "\n",
    "        ffn = keras.Sequential(ffn_layers)\n",
    "        return ffn\n",
    "    \n",
    "    def create_cross_attention_module(self,latent_dim, data_dim,\\\n",
    "                    projection_dim, ffn_units, dropout_rate):\n",
    "\n",
    "        inputs = {\n",
    "            # Recieve the latent array as an input of shape [1, latent_dim, projection_dim].\n",
    "            \"latent_array\": layers.Input(shape=(latent_dim, projection_dim)),\n",
    "            # Recieve the data_array (encoded image) as an input of shape [batch_size, data_dim, projection_dim].\n",
    "            \"data_array\": layers.Input(shape=(data_dim, projection_dim)),\n",
    "        }\n",
    "\n",
    "        # Apply layer norm to the inputs\n",
    "        latent_array = layers.LayerNormalization(epsilon=1e-6)(inputs[\"latent_array\"])\n",
    "        data_array = layers.LayerNormalization(epsilon=1e-6)(inputs[\"data_array\"])\n",
    "\n",
    "        # Create query tensor: [1, latent_dim, projection_dim].\n",
    "        query = layers.Dense(units=projection_dim)(latent_array)\n",
    "        # Create key tensor: [batch_size, data_dim, projection_dim].\n",
    "        key = layers.Dense(units=projection_dim)(data_array)\n",
    "        # Create value tensor: [batch_size, data_dim, projection_dim].\n",
    "        value = layers.Dense(units=projection_dim)(data_array)\n",
    "\n",
    "        # Generate cross-attention outputs: [batch_size, latent_dim, projection_dim].\n",
    "        attention_output = layers.Attention(use_scale=True, dropout=0.1)(\n",
    "            [query, key, value], return_attention_scores=False\n",
    "        )\n",
    "        # Skip connection 1.\n",
    "        attention_output = layers.Add()([attention_output, latent_array])\n",
    "\n",
    "        # Apply layer norm.\n",
    "        attention_output = layers.LayerNormalization(epsilon=1e-6)(attention_output)\n",
    "        # Apply Feedforward network.\n",
    "        ffn = self.create_ffn(hidden_units=ffn_units, dropout_rate=dropout_rate)\n",
    "        outputs = ffn(attention_output)\n",
    "        # Skip connection 2.\n",
    "        outputs = layers.Add()([outputs, attention_output])\n",
    "\n",
    "        # Create the Keras model.\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        return model\n",
    "    \n",
    "    def create_transformer_module(self,latent_dim,projection_dim,num_heads,\\\n",
    "        num_transformer_blocks,ffn_units,dropout_rate,):\n",
    "\n",
    "        # input_shape: [1, latent_dim, projection_dim]\n",
    "        inputs = layers.Input(shape=(latent_dim, projection_dim))\n",
    "\n",
    "        x0 = inputs\n",
    "        # Create multiple layers of the Transformer block.\n",
    "        for _ in range(num_transformer_blocks):\n",
    "            # Apply layer normalization 1.\n",
    "            x1 = layers.LayerNormalization(epsilon=1e-6)(x0)\n",
    "            # Create a multi-head self-attention layer.\n",
    "            attention_output = layers.MultiHeadAttention(\n",
    "                num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "            )(x1, x1)\n",
    "            # Skip connection 1.\n",
    "            x2 = layers.Add()([attention_output, x0])\n",
    "            # Apply layer normalization 2.\n",
    "            x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "            # Apply Feedforward network.\n",
    "            ffn = self.create_ffn(hidden_units=ffn_units, dropout_rate=dropout_rate)\n",
    "            x3 = ffn(x3)\n",
    "            # Skip connection 2.\n",
    "            x0 = layers.Add()([x3, x2])\n",
    "\n",
    "        # Create the Keras model.\n",
    "        model = keras.Model(inputs=inputs, outputs=x0)\n",
    "        return model\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create latent array.\n",
    "        self.latent_array = self.add_weight(\n",
    "            shape=(self.latent_dim, self.projection_dim),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        # Create cross-attenion module.\n",
    "        self.cross_attention = self.create_cross_attention_module(\n",
    "            self.latent_dim,\n",
    "            self.data_dim,\n",
    "            self.projection_dim,\n",
    "            self.ffn_units ,\n",
    "            self.dropout_rate,\n",
    "        )\n",
    "\n",
    "        # Create Transformer module.\n",
    "        self.transformer = self.create_transformer_module(\n",
    "            self.latent_dim,\n",
    "            self.projection_dim,\n",
    "            self.num_heads,\n",
    "            self.num_transformer_blocks,\n",
    "            self.ffn_units,\n",
    "            self.dropout_rate,\n",
    "        )\n",
    "        \n",
    "        super(Perceiver2D, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Prepare cross-attention inputs.\n",
    "        cross_attention_inputs = {\n",
    "            \"latent_array\": tf.expand_dims(self.latent_array, 0),\n",
    "            \"data_array\": inputs,\n",
    "        }\n",
    "        # Apply the cross-attention and the Transformer modules iteratively.\n",
    "        for _ in range(num_iterations):\n",
    "            # Apply cross-attention from the latent array to the data array.\n",
    "            latent_array = self.cross_attention(cross_attention_inputs)\n",
    "            # Apply self-attention Transformer to the latent array.\n",
    "            latent_array = self.transformer(latent_array)\n",
    "            # Set the latent array of the next iteration.\n",
    "            cross_attention_inputs[\"latent_array\"] = latent_array\n",
    "            \n",
    "        return latent_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e17de99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"perceiver2d\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model (Functional)           (None, 256, 256)          330497    \n",
      "_________________________________________________________________\n",
      "model_1 (Functional)         (None, 256, 256)          8944640   \n",
      "=================================================================\n",
      "Total params: 9,340,673\n",
      "Trainable params: 9,340,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "dropout_rate = 0.2\n",
    "\n",
    "data_dim = 512\n",
    "latent_dim = 256  # Size of the latent array.\n",
    "projection_dim = 256  # Embedding size of each element in the data and latent arrays.\n",
    "num_heads = 8  # Number of Transformer heads.\n",
    "\n",
    "ffn_units = [\n",
    "    projection_dim,\n",
    "    projection_dim,\n",
    "]  # Dim of the Feedforward network.\n",
    "\n",
    "num_transformer_blocks = 4\n",
    "num_iterations = 3\n",
    "\n",
    "model = Perceiver2D(\n",
    "        data_dim,\n",
    "        latent_dim,\n",
    "        projection_dim,\n",
    "        num_heads,\n",
    "        num_transformer_blocks,\n",
    "        ffn_units,\n",
    "        dropout_rate,\n",
    "        num_iterations,\n",
    ")\n",
    "model.build((None,512,256))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47c052de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perciever 2D operation test passed!!!\n"
     ]
    }
   ],
   "source": [
    "x = np.random.uniform(0,1,(1,512,256))\n",
    "yh = model(x)\n",
    "if yh.shape != (1, 256, 256):\n",
    "    raise ValueError('Perciever 2D output is the wrong size!!!')\n",
    "else:\n",
    "    print(\"Perciever 2D operation test passed!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34538d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d31e0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad5d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61426ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8482f656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d503d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2239690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfp-env",
   "language": "python",
   "name": "anaconda-tfp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
