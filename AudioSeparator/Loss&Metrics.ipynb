{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d7cc008",
   "metadata": {},
   "source": [
    "# Loss and Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3391e7",
   "metadata": {},
   "source": [
    "## To Do\n",
    "* check sinri and sdri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bdaada",
   "metadata": {},
   "source": [
    "## Resources\n",
    "* https://github.com/aliutkus/speechmetrics\n",
    "* https://source-separation.github.io/tutorial/landing.html\n",
    "* https://github.com/r06944010/Speech-Separation-TF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce02b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mir_eval.separation import bss_eval_sources\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import permutations\n",
    "\n",
    "import evaluation\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad4dde68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3,)\n",
      "(1, 2, 3)\n",
      "(1, 2, 3)\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "# Batch size of 1\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "s1 = np.array([1,2,1.5],dtype='float32')\n",
    "s2 = np.array([3,4,4.5],dtype='float32')\n",
    "s = np.stack([s1,s2])\n",
    "s = np.reshape(s,(1,2,3))\n",
    "mix_s = np.sum(np.stack([s1,s2]),axis=0)\n",
    "mix_s = mix_s.reshape(1,3)\n",
    "\n",
    "s1_est = np.array([1.4,1.8,1.7],dtype='float32')\n",
    "s2_est = np.array([3.2,4.5,4.1],dtype='float32')\n",
    "s_est = np.stack([s1_est,s2_est])\n",
    "s_est = np.reshape(s_est,(1,2,3))\n",
    "\n",
    "print(s1.shape)\n",
    "print(s2.shape)\n",
    "print(s.shape)\n",
    "print(s_est.shape)\n",
    "print(mix_s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33c6524e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(2, 2, 3)\n",
      "(2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "# Batch size of 2 copy \n",
    "BATCH_SIZE = 2\n",
    "\n",
    "s1a = np.array([1,2,1.5],dtype='float32')\n",
    "s2a = np.array([3,4,4.5],dtype='float32')\n",
    "sa = np.stack([s1a,s2a])\n",
    "sa = np.reshape(sa,(1,2,3))\n",
    "mix_sa = np.sum(np.stack([s1a,s2a]),axis=0)\n",
    "\n",
    "s1b = np.array([1,2,1.5],dtype='float32')\n",
    "s2b = np.array([3,4,4.5],dtype='float32')\n",
    "sb = np.stack([s1b,s2b])\n",
    "sb = np.reshape(sb,(1,2,3))\n",
    "mix_sb = np.sum(np.stack([s1b,s2b]),axis=0)\n",
    "\n",
    "mix_s = np.stack([mix_sa,mix_sb])\n",
    "s = np.concatenate([sa,sb],axis=0)\n",
    "print(mix_s.shape)\n",
    "print(s.shape)\n",
    "\n",
    "s1a_est = np.array([1.4,1.8,1.7],dtype='float32')\n",
    "s2a_est = np.array([3.2,4.5,4.1],dtype='float32')\n",
    "\n",
    "s1b_est = np.array([1.4,1.8,1.7],dtype='float32')\n",
    "s2b_est = np.array([3.2,4.5,4.1],dtype='float32')\n",
    "\n",
    "sa_est = np.stack([s1a_est,s2a_est])\n",
    "sa_est = np.reshape(sa_est,(1,2,3))\n",
    "\n",
    "sb_est = np.stack([s1b_est,s2b_est])\n",
    "sb_est = np.reshape(sb_est,(1,2,3))\n",
    "\n",
    "s_est = np.concatenate([sa_est,sb_est],axis=0)\n",
    "print(s_est.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16d6a453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(2, 2, 3)\n",
      "(2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "# Batch size of 2\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "s1a = np.array([1,2,1.5],dtype='float32')\n",
    "s2a = np.array([3,4,4.5],dtype='float32')\n",
    "sa = np.stack([s1a,s2a])\n",
    "sa = np.reshape(sa,(1,2,3))\n",
    "mix_sa = np.sum(np.stack([s1a,s2a]),axis=0)\n",
    "\n",
    "s1b = np.array([3,2.5,5],dtype='float32')\n",
    "s2b = np.array([1,2,4],dtype='float32')\n",
    "sb = np.stack([s1b,s2b])\n",
    "sb = np.reshape(sb,(1,2,3))\n",
    "mix_sb = np.sum(np.stack([s1b,s2b]),axis=0)\n",
    "\n",
    "mix_s = np.stack([mix_sa,mix_sb])\n",
    "s = np.concatenate([sa,sb],axis=0)\n",
    "print(mix_s.shape)\n",
    "print(s.shape)\n",
    "\n",
    "\n",
    "s1a_est = np.array([1.4,1.8,1.7],dtype='float32')\n",
    "s2a_est = np.array([3.2,4.5,4.1],dtype='float32')\n",
    "\n",
    "s1b_est = np.array([2.8,2,4.7],dtype='float32')\n",
    "s2b_est = np.array([1.4,2.3,4.2],dtype='float32')\n",
    "\n",
    "sa_est = np.stack([s1a_est,s2a_est])\n",
    "sa_est = np.reshape(sa_est,(1,2,3))\n",
    "\n",
    "sb_est = np.stack([s1b_est,s2b_est])\n",
    "sb_est = np.reshape(sb_est,(1,2,3))\n",
    "\n",
    "s_est = np.concatenate([sa_est,sb_est],axis=0)\n",
    "print(s_est.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24717276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIN THE WORKS, NOT STABLE!!!\\n\\n@tf.function\\ndef get_permutation_invariant_sisnr(spk0_estimate, spk1_estimate, spk0_groundtruth, spk1_groundtruth):\\n    perm0_spk0 = sisnr(spk0_groundtruth, spk0_estimate, do_expand=True)\\n    perm0_spk1 = sisnr(spk1_groundtruth, spk1_estimate, do_expand=True)\\n    perm1_spk0 = sisnr(spk0_groundtruth, spk1_estimate, do_expand=True)\\n    perm1_spk1 = sisnr(spk1_groundtruth, spk0_estimate, do_expand=True)\\n\\n    # Get best permutation\\n    if perm0_spk0 + perm0_spk1 > perm1_spk0 + perm1_spk1:\\n        return perm0_spk0, perm0_spk1\\n\\n    return perm1_spk0, perm1_spk1 \\n\\n\\n@tf.function\\ndef permutation_invariant_loss(y_true, y_pred,n_sources=2):\\n    # PIT for n-sources, work but very slow, needs to use tf.while_loop\\n    # yet, implementing tf.while_loop is a nightmare\\n    sn, sn_hat = [], []\\n    for i in range(n_sources):\\n        sn.append(y_true[:,i,:])\\n        sn_hat.append(y_pred[:,i,:])\\n        \\n    perm = list(permutations(range(n_sources)))\\n    sisnr_perm = []\\n        \\n    for i in range(len(perm)):\\n        sisnr_perm_spk = [sisnr(sn[p], sn_hat[j]) for p,j in enumerate(perm[i])]\\n        sisnr_perm.append(tf.math.reduce_sum(sisnr_perm_spk)/n_sources)\\n\\n    sisnr_perm = tf.stack(sisnr_perm) \\n    return -tf.math.reduce_max(sisnr_perm)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def log10(x):\n",
    "    numerator = tf.math.log(x)\n",
    "    denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\n",
    "    return numerator / denominator\n",
    "\n",
    "def sisnr(s, s_hat, do_expand=False, eps=1e-8):\n",
    "    if do_expand:\n",
    "        s = np.expand_dims(s, axis=0)\n",
    "        s_hat = np.expand_dims(s_hat, axis=0)\n",
    "    dot_product = tf.math.reduce_sum(s*s_hat, axis=1, keepdims=True)\n",
    "    squares = tf.math.reduce_sum(s*s, axis=1, keepdims=True)\n",
    "    s_target = s * dot_product / squares\n",
    "    e_noise = s_hat - s_target\n",
    "    s_target_squared = tf.math.reduce_sum(s_target*s_target, axis=1)\n",
    "    e_noise_squared = tf.math.reduce_sum(e_noise*e_noise, axis=1)\n",
    "    return 10*log10(s_target_squared / (e_noise_squared + eps))\n",
    "\n",
    "def pit_sisnr(y_true, y_pred,n_sources=2):\n",
    "    y_mix = tf.math.reduce_sum(y_true,axis=1,keepdims=False)\n",
    "\n",
    "    sn, sn_hat = [], []\n",
    "    for i in range(n_sources):\n",
    "        sn.append(y_true[:,i,:])\n",
    "        sn_hat.append(y_pred[:,i,:])\n",
    "    \n",
    "    if n_sources == 2:\n",
    "        sisnr_perm0_spk0 = sisnr(sn[0], sn_hat[0])\n",
    "        sisnr_perm0_spk1 = sisnr(sn[1], sn_hat[1])\n",
    "        sisnr_perm0 = (sisnr_perm0_spk0 + sisnr_perm0_spk1) / 2\n",
    "\n",
    "        sisnr_perm1_spk0 = sisnr(sn[0], sn_hat[1])\n",
    "        sisnr_perm1_spk1 = sisnr(sn[1], sn_hat[0])\n",
    "        sisnr_perm1 = (sisnr_perm1_spk0 + sisnr_perm1_spk1) / 2\n",
    "\n",
    "        sisnr_perm_invariant = tf.math.maximum(sisnr_perm0, sisnr_perm1)\n",
    "        \n",
    "        print(sn[0].shape)\n",
    "        sisnr_b1 = sisnr(sn[0],y_mix)\n",
    "        sisnr_b2 = sisnr(sn[1],y_mix)\n",
    "        avg_SISNRi = ((sisnr_perm0_spk0 - sisnr_b1) + (sisnr_perm0_spk1 - sisnr_b2)) / 2\n",
    "        \n",
    "        return tf.math.reduce_mean(sisnr_perm_invariant), -1*avg_SISNRi \n",
    "    \n",
    "    elif n_sources == 3:\n",
    "        sisnr_perm0_spk0 = sisnr(sn[0], sn_hat[0])\n",
    "        sisnr_perm0_spk1 = sisnr(sn[1], sn_hat[1])\n",
    "        sisnr_perm0_spk2 = sisnr(sn[2], sn_hat[2])\n",
    "        sisnr_perm0 = (sisnr_perm0_spk0 + sisnr_perm0_spk1 + sisnr_perm0_spk2) / 3\n",
    "\n",
    "        sisnr_perm1_spk0 = sisnr(sn[0], sn_hat[0])\n",
    "        sisnr_perm1_spk1 = sisnr(sn[1], sn_hat[2])\n",
    "        sisnr_perm1_spk2 = sisnr(sn[2], sn_hat[1])\n",
    "        sisnr_perm1 = (sisnr_perm1_spk0 + sisnr_perm1_spk1 + sisnr_perm1_spk2) / 3\n",
    "        \n",
    "        sisnr_perm2_spk0 = sisnr(sn[0], sn_hat[1])\n",
    "        sisnr_perm2_spk1 = sisnr(sn[1], sn_hat[0])\n",
    "        sisnr_perm2_spk2 = sisnr(sn[2], sn_hat[2])\n",
    "        sisnr_perm2 = (sisnr_perm2_spk0 + sisnr_perm2_spk1 + sisnr_perm2_spk2) / 3\n",
    "        \n",
    "        sisnr_perm3_spk0 = sisnr(sn[0], sn_hat[1])\n",
    "        sisnr_perm3_spk1 = sisnr(sn[1], sn_hat[2])\n",
    "        sisnr_perm3_spk2 = sisnr(sn[2], sn_hat[0])\n",
    "        sisnr_perm3 = (sisnr_perm3_spk0 + sisnr_perm3_spk1 + sisnr_perm3_spk2) / 3\n",
    "        \n",
    "        sisnr_perm4_spk0 = sisnr(sn[0], sn_hat[2])\n",
    "        sisnr_perm4_spk1 = sisnr(sn[1], sn_hat[0])\n",
    "        sisnr_perm4_spk2 = sisnr(sn[2], sn_hat[1])\n",
    "        sisnr_perm4 = (sisnr_perm4_spk0 + sisnr_perm4_spk1 + sisnr_perm4_spk2) / 3\n",
    "        \n",
    "        sisnr_perm5_spk0 = sisnr(sn[0], sn_hat[2])\n",
    "        sisnr_perm5_spk1 = sisnr(sn[1], sn_hat[1])\n",
    "        sisnr_perm5_spk2 = sisnr(sn[2], sn_hat[0])\n",
    "        sisnr_perm5 = (sisnr_perm5_spk0 + sisnr_perm5_spk1 + sisnr_perm5_spk2) / 3\n",
    "        \n",
    "        sisnr_perm_invariant = tf.stack([sisnr_perm1,sisnr_perm2,sisnr_perm3,sisnr_perm4,sisnr_perm5])\n",
    "        sisnr_perm_invariant = tf.math.reduce_max(sisnr_perm_invariant)\n",
    "        return tf.math.reduce_mean(sisnr_perm_invariant)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "IN THE WORKS, NOT STABLE!!!\n",
    "\n",
    "@tf.function\n",
    "def get_permutation_invariant_sisnr(spk0_estimate, spk1_estimate, spk0_groundtruth, spk1_groundtruth):\n",
    "    perm0_spk0 = sisnr(spk0_groundtruth, spk0_estimate, do_expand=True)\n",
    "    perm0_spk1 = sisnr(spk1_groundtruth, spk1_estimate, do_expand=True)\n",
    "    perm1_spk0 = sisnr(spk0_groundtruth, spk1_estimate, do_expand=True)\n",
    "    perm1_spk1 = sisnr(spk1_groundtruth, spk0_estimate, do_expand=True)\n",
    "\n",
    "    # Get best permutation\n",
    "    if perm0_spk0 + perm0_spk1 > perm1_spk0 + perm1_spk1:\n",
    "        return perm0_spk0, perm0_spk1\n",
    "\n",
    "    return perm1_spk0, perm1_spk1 \n",
    "\n",
    "\n",
    "@tf.function\n",
    "def permutation_invariant_loss(y_true, y_pred,n_sources=2):\n",
    "    # PIT for n-sources, work but very slow, needs to use tf.while_loop\n",
    "    # yet, implementing tf.while_loop is a nightmare\n",
    "    sn, sn_hat = [], []\n",
    "    for i in range(n_sources):\n",
    "        sn.append(y_true[:,i,:])\n",
    "        sn_hat.append(y_pred[:,i,:])\n",
    "        \n",
    "    perm = list(permutations(range(n_sources)))\n",
    "    sisnr_perm = []\n",
    "        \n",
    "    for i in range(len(perm)):\n",
    "        sisnr_perm_spk = [sisnr(sn[p], sn_hat[j]) for p,j in enumerate(perm[i])]\n",
    "        sisnr_perm.append(tf.math.reduce_sum(sisnr_perm_spk)/n_sources)\n",
    "\n",
    "    sisnr_perm = tf.stack(sisnr_perm) \n",
    "    return -tf.math.reduce_max(sisnr_perm)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e5a3383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pit_loss(y_true, y_pred, loss_type, batch_size, n_speaker, n_output, pit_axis=1):\n",
    "    # [batch, spk #, length]\n",
    "    real_spk_num = n_speaker\n",
    "\n",
    "    # TODO 1: # output channel != # speaker\n",
    "    v_perms = tf.constant(list(itertools.permutations(range(n_output), n_speaker)))\n",
    "    v_perms_onehot = tf.one_hot(v_perms, n_output)\n",
    "\n",
    "    y_true_exp = tf.expand_dims(y_true, pit_axis+1) # [batch, n_speaker, 1,        len]\n",
    "    y_pred_exp = tf.expand_dims(y_pred, pit_axis)   # [batch, 1,         n_output, len]\n",
    "\n",
    "    cross_total_loss = get_loss(loss_type, y_true_exp, y_pred_exp)\n",
    "\n",
    "    loss_sets = tf.einsum('bij,pij->bp', cross_total_loss, v_perms_onehot) \n",
    "    loss = tf.reduce_min(loss_sets, axis=1)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "        \n",
    "    # find permutation sets for y pred\n",
    "    s_perm_sets = tf.argmin(loss_sets, 1)\n",
    "    s_perm_choose = tf.gather(v_perms, s_perm_sets)\n",
    "    s_perm_idxs = tf.stack([\n",
    "        tf.tile(\n",
    "            tf.expand_dims(tf.range(batch_size), 1),\n",
    "            [1, n_speaker]),\n",
    "        s_perm_choose], axis=2)\n",
    "\n",
    "    s_perm_idxs = tf.reshape(s_perm_idxs, [batch_size*n_speaker, 2])\n",
    "    y_pred = tf.gather_nd(y_pred, s_perm_idxs)\n",
    "    y_pred = tf.reshape(y_pred, [batch_size, n_speaker, -1])\n",
    "\n",
    "    if loss_type != 'sdr':\n",
    "        sdr = evaluation.sdr(y_true[:,:real_spk_num,:], y_pred[:,:real_spk_num,:])\n",
    "        sdr = tf.reduce_mean(sdr)\n",
    "    else:\n",
    "        sdr = -loss/n_speaker\n",
    "\n",
    "    return loss, y_pred, sdr, s_perm_choose\n",
    "\n",
    "def get_loss(loss_type, t_true_exp, t_pred_exp, axis=-1):\n",
    "    if loss_type == 'l1':\n",
    "        y_cross_loss = t_true_exp - t_pred_exp\n",
    "        cross_total_loss = tf.reduce_sum(tf.abs(y_cross_loss), axis=axis)\n",
    "\n",
    "    elif loss_type == 'l2':\n",
    "        y_cross_loss = t_true_exp - t_pred_exp\n",
    "        cross_total_loss = tf.reduce_sum(tf.square(y_cross_loss), axis=axis)\n",
    "\n",
    "    elif loss_type == 'snr':\n",
    "        cross_total_loss = -evaluation.snr(t_true_exp, t_pred_exp)\n",
    "\n",
    "    elif loss_type == 'sdr':\n",
    "        cross_total_loss = -evaluation.sdr(t_true_exp, t_pred_exp)\n",
    "\n",
    "    elif loss_type == 'sisnr':\n",
    "        cross_total_loss = -evaluation.sisnr(t_true_exp, t_pred_exp)\n",
    "\n",
    "    elif loss_type == 'sdr_modify':\n",
    "        cross_total_loss = -evaluation.sdr_modify(t_true_exp, t_pred_exp)\n",
    "\n",
    "    elif loss_type == 'sisdr':\n",
    "        cross_total_loss = -evaluation.sisdr(t_true_exp, t_pred_exp)\n",
    "\n",
    "    elif loss_type == 'sym_sisdr':\n",
    "        cross_total_loss = -evaluation.sym_sisdr(t_true_exp, t_pred_exp)\n",
    "\n",
    "    return cross_total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "764bc2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-37.075935, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[3.2 4.5 4.1]\n",
      "  [1.4 1.8 1.7]]\n",
      "\n",
      " [[2.8 2.  4.7]\n",
      "  [1.4 2.3 4.2]]], shape=(2, 2, 3), dtype=float32)\n",
      "tf.Tensor(21.44663, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1 0]\n",
      " [0 1]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "loss, y_pred, sdr, s_perm_choose = pit_loss(s, s_est, 'sisnr', BATCH_SIZE, 2, 2, pit_axis=1)\n",
    "print(loss)\n",
    "print(y_pred)\n",
    "print(sdr)\n",
    "print(s_perm_choose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3062b934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sisnri(s, s_est, mix_s, batch_size, n_speaker, n_output, pit_axis=1):\n",
    "    mix_s = tf.repeat(mix_s,n_speaker,axis=1) \n",
    "    mix_s = tf.reshape(mix_s,(batch_size,n_speaker,-1))\n",
    "    \n",
    "    loss, _, _, _ = pit_loss(s, s_est,  'sisnr', batch_size, n_speaker, n_output, pit_axis=1)\n",
    "    loss_b, _, _, _ = pit_loss(s, mix_s, 'sisnr', batch_size, n_speaker, n_output, pit_axis=1)\n",
    "    if tf.math.is_nan(loss_b):\n",
    "        return loss*-1\n",
    "\n",
    "    loss *= -1\n",
    "    loss_b *= -1\n",
    "    return loss-loss_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0163723d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(37.075935, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "loss = sisnri(s, s_est, mix_s,  BATCH_SIZE, 2, 2, pit_axis=1)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28b0753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdri(s, s_est, mix_s, batch_size, n_speaker, n_output, pit_axis=1):\n",
    "    mix_s = tf.repeat(mix_s,n_speaker,axis=1) \n",
    "    mix_s = tf.reshape(mix_s,(batch_size,n_speaker,-1))\n",
    "    \n",
    "    loss, _, sdr, _ = pit_loss(s, s_est,  'sdr', batch_size, n_speaker, n_output, pit_axis=1)\n",
    "    loss_b, _, sdr_b, _ = pit_loss(s, mix_s, 'sdr', batch_size, n_speaker, n_output, pit_axis=1)\n",
    "    \n",
    "    if tf.math.is_nan(sdr_b):\n",
    "        return sdr   \n",
    "    \n",
    "    return sdr-sdr_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "930eb96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(8.873157, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "loss = sdri(s, s_est, mix_s, BATCH_SIZE, 2, 2, pit_axis=1)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec94c3ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88efa984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfp-env",
   "language": "python",
   "name": "anaconda-tfp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
